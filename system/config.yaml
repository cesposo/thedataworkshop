# Controller configuration
controller:
  host: localhost
  port: 8000
  scheduler: priority
  use_lattice: false  # Enable lattice-aware scheduling
  max_lattice_size: 100  # Maximum stable matchings to enumerate
  lattice_rebuild_interval: 300  # Seconds before preferences considered stale

# Learned preference configuration
preferences:
  mode: heuristic  # 'heuristic' or 'learned'
  model_path: null  # Path to trained PerformancePredictor model (e.g., 'models/predictor.pkl')
  objective: throughput  # 'throughput', 'latency', or 'balanced'
  history_db: training_history.db  # SQLite database for training run history

# Worker configuration
workers:
  - name: worker-1
    memory: 16
    flops_per_second: 100
    network_bandwidth: 1000
    host: localhost
    port: 8001
  - name: worker-2
    memory: 32
    flops_per_second: 200
    network_bandwidth: 1000
    host: localhost
    port: 8002

# Model configuration
model:
  name: tiny-lstm

# Training configuration
training:
  learning_rate: 0.001
  batch_size: 8
  num_epochs: 1 # Reduced from 2
  num_samples: 10 # Reduced from 50
  seq_length: 32
  num_workers: 2

# Task configuration
tasks:
  - id: ml-task-0
    model_shard_size: 0.5
    data_size: 0.1
    required_flops: 1000
    priority: 1
  - id: ml-task-1
    model_shard_size: 0.5
    data_size: 0.1
    required_flops: 1000
    priority: 2

# Simulation configuration
simulation:
  heartbeat_cycles: 5 # Reduced from 30
  heartbeat_interval: 1 # Reduced from 5
  scheduling_cycles: 3 # Reduced from 5
  scheduling_interval: 2 # Reduced from 15